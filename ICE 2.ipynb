{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb2934d",
   "metadata": {},
   "source": [
    "HUDK 4051\n",
    "\n",
    "Yiran Wang\n",
    "\n",
    "2022/03/22\n",
    "\n",
    "# ICE 2 Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf84749",
   "metadata": {},
   "source": [
    "#### Objectives:\n",
    "\n",
    "At the end of this ICE, you will demonstrate that you will be able to:\n",
    "\n",
    "- perform basic data cleaning related to NLP\n",
    "- build basic tokenized document-term matrix for analysis\n",
    "- run basic exploratory analysis with document-term matrix\n",
    "- implement LDA topic modeling\n",
    "- implement basic text classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97881f",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation etc. Obviously, we won't be able to cover everything in one ICE. This ICE intent to introduce you to some basics of NLP techniques.\n",
    "\n",
    "In particular, in this ICE, we will (a) use LDA to model the topics in the comments, and (b) train a simple classifier to predict the evaluation based on the comment.\n",
    "\n",
    "To start with, we will load the data. This dataset is collected from the students of a prominent university in North India. This dataset should be used to create the overall Institutional Report on the basis of student feedback data. The data source can be found here: https://www.kaggle.com/brarajit18/student-feedback-dataset\n",
    "\n",
    "This dataset is comprised of 6 categories, which includes teaching, course content, examination, lab work, library facilities and extra curricular activities. Data for each category includes two columns, where each column can have any of the three labels, i.e. 0 (neutral), 1 (positive) and -1 (negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e1c7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d711800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teaching</th>\n",
       "      <th>teaching.1</th>\n",
       "      <th>coursecontent</th>\n",
       "      <th>coursecontent.1</th>\n",
       "      <th>examination</th>\n",
       "      <th>Examination</th>\n",
       "      <th>labwork</th>\n",
       "      <th>labwork.1</th>\n",
       "      <th>library_facilities</th>\n",
       "      <th>library_facilities</th>\n",
       "      <th>extracurricular</th>\n",
       "      <th>extracurricular.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "      <td>0</td>\n",
       "      <td>content of courses are average</td>\n",
       "      <td>1</td>\n",
       "      <td>examination pattern is good</td>\n",
       "      <td>-1</td>\n",
       "      <td>not satisfactory, lab work must include latest...</td>\n",
       "      <td>0</td>\n",
       "      <td>library facilities are good but number of book...</td>\n",
       "      <td>1</td>\n",
       "      <td>extracurricular activities are excellent and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>-1</td>\n",
       "      <td>Not good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>-1</td>\n",
       "      <td>Not good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "      <td>1</td>\n",
       "      <td>All courses material provide very good knowled...</td>\n",
       "      <td>1</td>\n",
       "      <td>Exam pattern is up to the mark and the Cgpa de...</td>\n",
       "      <td>1</td>\n",
       "      <td>Lab work is properly covered in the labs by th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Library facilities are excellent in terms of g...</td>\n",
       "      <td>1</td>\n",
       "      <td>Extra curricular activities also help students...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>-1</td>\n",
       "      <td>Content of course is perfectly in line with th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Again the university tests students of their a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>Its the best thing i have seen in this univers...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Complete wastage of time. Again this opinion i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "      <td>1</td>\n",
       "      <td>content of courses improves my knowledge</td>\n",
       "      <td>1</td>\n",
       "      <td>examination pattern is good</td>\n",
       "      <td>1</td>\n",
       "      <td>practical work provides detail knowledge of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>library has huge collection of books from diff...</td>\n",
       "      <td>1</td>\n",
       "      <td>extracurricular activities increases mental an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>intraction is good and leacture delivery also ...</td>\n",
       "      <td>0</td>\n",
       "      <td>every one can tell depth of course but some on...</td>\n",
       "      <td>0</td>\n",
       "      <td>exam pattern is good and marks distribution is...</td>\n",
       "      <td>1</td>\n",
       "      <td>all labs and practical going on well</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>1</td>\n",
       "      <td>they all are held in super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>all the given terms are good regarding the uni...</td>\n",
       "      <td>1</td>\n",
       "      <td>we are getting maximum knowledge</td>\n",
       "      <td>1</td>\n",
       "      <td>all are good</td>\n",
       "      <td>1</td>\n",
       "      <td>not bad</td>\n",
       "      <td>-1</td>\n",
       "      <td>library facilities are not good.They are not f...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>All the terms are good regarding the universit...</td>\n",
       "      <td>1</td>\n",
       "      <td>Knowledge is maximum gained  by reading books ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The examination pattern is good .But time is n...</td>\n",
       "      <td>1</td>\n",
       "      <td>Labs are upto the mark.</td>\n",
       "      <td>1</td>\n",
       "      <td>They are good</td>\n",
       "      <td>1</td>\n",
       "      <td>the extracurricular activities held in univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1</td>\n",
       "      <td>Some of the teacher are un experienced. Also t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Its fine but it should focus more towards prac...</td>\n",
       "      <td>1</td>\n",
       "      <td>MCQ pattern is quite good and efficient way fo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Our labs do not have all facalities.</td>\n",
       "      <td>1</td>\n",
       "      <td>We have a good library with all facalities.</td>\n",
       "      <td>1</td>\n",
       "      <td>Our university has lot of extracurricular goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>IT IS GOING GOOD</td>\n",
       "      <td>-1</td>\n",
       "      <td>HAVE TO IMPROVE</td>\n",
       "      <td>0</td>\n",
       "      <td>PAPER CHECKING IS VERY HARD REMAINING IS GOOD</td>\n",
       "      <td>1</td>\n",
       "      <td>ALL PRACTICAL WORK IS GOOD</td>\n",
       "      <td>-1</td>\n",
       "      <td>THEY IS NO PROBLEM WITH THEM\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>IT IS THE BEST THING IN THIS UNIVERSITY I LIKE IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     teaching                                         teaching.1  \\\n",
       "0           0  teacher are punctual but they should also give...   \n",
       "1           1                                              Good    \n",
       "2           1  Excellent lectures are delivered by teachers a...   \n",
       "3           1                                               Good   \n",
       "4           1  teachers give us all the information required ...   \n",
       "..        ...                                                ...   \n",
       "180         1  intraction is good and leacture delivery also ...   \n",
       "181         1  all the given terms are good regarding the uni...   \n",
       "182         1  All the terms are good regarding the universit...   \n",
       "183        -1  Some of the teacher are un experienced. Also t...   \n",
       "184         1                                   IT IS GOING GOOD   \n",
       "\n",
       "     coursecontent                                    coursecontent.1  \\\n",
       "0                0                     content of courses are average   \n",
       "1               -1                                           Not good   \n",
       "2                1  All courses material provide very good knowled...   \n",
       "3               -1  Content of course is perfectly in line with th...   \n",
       "4                1           content of courses improves my knowledge   \n",
       "..             ...                                                ...   \n",
       "180              0  every one can tell depth of course but some on...   \n",
       "181              1                  we are getting maximum knowledge    \n",
       "182              1  Knowledge is maximum gained  by reading books ...   \n",
       "183              0  Its fine but it should focus more towards prac...   \n",
       "184             -1                                    HAVE TO IMPROVE   \n",
       "\n",
       "     examination                                        Examination  labwork  \\\n",
       "0              1                        examination pattern is good       -1   \n",
       "1              1                                               Good        1   \n",
       "2              1  Exam pattern is up to the mark and the Cgpa de...        1   \n",
       "3             -1  Again the university tests students of their a...        1   \n",
       "4              1                        examination pattern is good        1   \n",
       "..           ...                                                ...      ...   \n",
       "180            0  exam pattern is good and marks distribution is...        1   \n",
       "181            1                                      all are good         1   \n",
       "182            0  The examination pattern is good .But time is n...        1   \n",
       "183            1  MCQ pattern is quite good and efficient way fo...       -1   \n",
       "184            0      PAPER CHECKING IS VERY HARD REMAINING IS GOOD        1   \n",
       "\n",
       "                                             labwork.1  library_facilities  \\\n",
       "0    not satisfactory, lab work must include latest...                   0   \n",
       "1                                                Good                   -1   \n",
       "2    Lab work is properly covered in the labs by th...                   1   \n",
       "3                                                 Good                   0   \n",
       "4    practical work provides detail knowledge of th...                   1   \n",
       "..                                                 ...                 ...   \n",
       "180               all labs and practical going on well                   1   \n",
       "181                                            not bad                  -1   \n",
       "182                            Labs are upto the mark.                   1   \n",
       "183              Our labs do not have all facalities.                    1   \n",
       "184                         ALL PRACTICAL WORK IS GOOD                  -1   \n",
       "\n",
       "                                    library_facilities  extracurricular  \\\n",
       "0    library facilities are good but number of book...                1   \n",
       "1                                            Not good                 1   \n",
       "2    Library facilities are excellent in terms of g...                1   \n",
       "3    Its the best thing i have seen in this univers...               -1   \n",
       "4    library has huge collection of books from diff...                1   \n",
       "..                                                 ...              ...   \n",
       "180                                              good                 1   \n",
       "181  library facilities are not good.They are not f...                1   \n",
       "182                                      They are good                1   \n",
       "183        We have a good library with all facalities.                1   \n",
       "184                     THEY IS NO PROBLEM WITH THEM\\n                1   \n",
       "\n",
       "                                     extracurricular.1  \n",
       "0    extracurricular activities are excellent and p...  \n",
       "1                                                Good   \n",
       "2    Extra curricular activities also help students...  \n",
       "3    Complete wastage of time. Again this opinion i...  \n",
       "4    extracurricular activities increases mental an...  \n",
       "..                                                 ...  \n",
       "180                         they all are held in super  \n",
       "181                                               good  \n",
       "182  the extracurricular activities held in univers...  \n",
       "183  Our university has lot of extracurricular goin...  \n",
       "184  IT IS THE BEST THING IN THIS UNIVERSITY I LIKE IT  \n",
       "\n",
       "[185 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval = pd.read_csv(\"ICE2_data_eval.csv\")\n",
    "Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a0768",
   "metadata": {},
   "source": [
    "## Data Cleaning and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b059062",
   "metadata": {},
   "source": [
    "The first step of NLP often involves with data cleaning and data wrangling.\n",
    "\n",
    "For example, the dataset has 185 rows and 12 columns, but the information is quite repetitive. So for the further analysis purposes, we can rearrange the data into a long format. Feel free to wrangle the data in any format or only use part of the data. This is just a practice ICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641c6d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teaching</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  eval\n",
       "0            teaching     0\n",
       "1            teaching     1\n",
       "2            teaching     1\n",
       "3            teaching     1\n",
       "4            teaching     1\n",
       "...               ...   ...\n",
       "1105  extracurricular     1\n",
       "1106  extracurricular     1\n",
       "1107  extracurricular     1\n",
       "1108  extracurricular     1\n",
       "1109  extracurricular     1\n",
       "\n",
       "[1110 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearrange the data into a long format.\n",
    "eval1 = pd.melt(Eval, value_vars=['teaching', 'coursecontent', 'examination', 'labwork', 'library_facilities', 'extracurricular'],\n",
    "             var_name='category', value_name='eval')\n",
    "eval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ecc055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>they all are held in super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>the extracurricular activities held in univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>Our university has lot of extracurricular goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>IT IS THE BEST THING IN THIS UNIVERSITY I LIKE IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment\n",
       "0     teacher are punctual but they should also give...\n",
       "1                                                 Good \n",
       "2     Excellent lectures are delivered by teachers a...\n",
       "3                                                  Good\n",
       "4     teachers give us all the information required ...\n",
       "...                                                 ...\n",
       "1105                         they all are held in super\n",
       "1106                                               good\n",
       "1107  the extracurricular activities held in univers...\n",
       "1108  Our university has lot of extracurricular goin...\n",
       "1109  IT IS THE BEST THING IN THIS UNIVERSITY I LIKE IT\n",
       "\n",
       "[1110 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval2 = pd.melt(Eval, value_vars=['teaching.1', 'coursecontent.1', 'Examination', 'labwork.1', 'library_facilities', 'extracurricular.1'],\n",
    "             var_name='category', value_name='comment')\n",
    "eval2.drop('category', axis=1, inplace=True)\n",
    "eval2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d915d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "      <td>teaching</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>they all are held in super</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>good</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>the extracurricular activities held in univers...</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>Our university has lot of extracurricular goin...</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>IT IS THE BEST THING IN THIS UNIVERSITY I LIKE IT</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment         category  eval\n",
       "0     teacher are punctual but they should also give...         teaching     0\n",
       "1                                                 Good          teaching     1\n",
       "2     Excellent lectures are delivered by teachers a...         teaching     1\n",
       "3                                                  Good         teaching     1\n",
       "4     teachers give us all the information required ...         teaching     1\n",
       "...                                                 ...              ...   ...\n",
       "1105                         they all are held in super  extracurricular     1\n",
       "1106                                               good  extracurricular     1\n",
       "1107  the extracurricular activities held in univers...  extracurricular     1\n",
       "1108  Our university has lot of extracurricular goin...  extracurricular     1\n",
       "1109  IT IS THE BEST THING IN THIS UNIVERSITY I LIKE IT  extracurricular     1\n",
       "\n",
       "[1110 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalClean = pd.concat([eval2, eval1], axis = 1)\n",
    "evalClean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83307aa4",
   "metadata": {},
   "source": [
    "Large part of the data cleaning in NLP is associated with presenting the data in a consistent format and removing words without substantial semantic meanings. So, common data cleaning methods you can do include: make text lowercase, remove formats (e.g., html labels), remove punctuation, and remove words containing numbers. Some of them are easy (e.g., make everything lowercase) while some of them might be trickier depending on how pretty your data is.\n",
    "\n",
    "Anyway, for this particular example, let's just make all the text into lowercase, remove the punctunations, and remove the numbers. I am encapsulate the data cleaning all in one function called clean_text() and then map() this function to comment.\n",
    "\n",
    "When removing the punctuation, you will often find regular expression or regex a very handy tool to use if you want to automate this process. In fact, regex will be a great addition to your toolbox not only for NLP tasks, but pretty much any Data Science job involves data cleaning. There are a lot of great resources to learn it (e.g., https://developers.google.com/edu/python/regular-expressions), but I suggest you mastering it as you use it. No need to spend a lot of time perfecting a complicated tool that you won't use regularly (yes, regex involves a lot of tricks and can get quite complicated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41568b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regex library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1594d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #Make text lowercase, remove punctuations, and remove numbers\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('[0-9]+','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bd7adf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "      <td>teaching</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent lectures are delivered by teachers a...</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "      <td>teaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>they all are held in super</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>good</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>the extracurricular activities held in univers...</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>our university has lot of extracurricular goin...</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>it is the best thing in this university i like it</td>\n",
       "      <td>extracurricular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment         category  eval\n",
       "0     teacher are punctual but they should also give...         teaching     0\n",
       "1                                                 good          teaching     1\n",
       "2     excellent lectures are delivered by teachers a...         teaching     1\n",
       "3                                                  good         teaching     1\n",
       "4     teachers give us all the information required ...         teaching     1\n",
       "...                                                 ...              ...   ...\n",
       "1105                         they all are held in super  extracurricular     1\n",
       "1106                                               good  extracurricular     1\n",
       "1107  the extracurricular activities held in univers...  extracurricular     1\n",
       "1108  our university has lot of extracurricular goin...  extracurricular     1\n",
       "1109  it is the best thing in this university i like it  extracurricular     1\n",
       "\n",
       "[1110 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "evalClean['comment'] = [str (item) for item in evalClean['comment']]\n",
    "\n",
    "evalClean['comment'] = evalClean['comment'].map(clean_text)\n",
    "evalClean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03411e5b",
   "metadata": {},
   "source": [
    "## Organizing Data\n",
    "\n",
    "Now, the data is almost ready to be analyzed. But before that, there are two important concepts for text formats you need to know:\n",
    "- **Corpus**: a collection of text\n",
    "- **Document-Term Matrix**: word counts in matrix format\n",
    "\n",
    "What we already have is a corpus. It is human-readable because it stores the data in a natural language style. However, For many of the techniques we'll be using, algorithms do not recognize our natural language. Particularly, the statistics tools we have been using/learning relies on processing quantifiable numbers.\n",
    "\n",
    "As a result, we need to tokenize the text/corpus, meaning broken the text down into smaller pieces. The most common tokenization technique is to break down text into words. Essentially, we are taking a dictionary of words and mark the occurence frequency and/or the order of each word for each text in the corpus. Then we can represent a corpus in the quantitative (but not quite human-readable) way. And it is called Document-Term Matrix, where every row will represent a different document and every column will represent a different word.\n",
    "\n",
    "You can imagine that once the documents get longer and complicated, we may be dealing with a very wide and sparse matrix, which is not ideal for any statistics modeling. Therefore, we have two more important concepts to help simplify the process\n",
    "\n",
    "1. **Bag-of-words**: We treat each document as a big bag of words. We don't necessarily care the orders of the words (i.e., grammar) at this stage. Just knowing the semantic meaning of each words can already tell us a lot. In fact, aoccdrnig to a rscheearch at Cmabrigde Uinervtisy, it deosn't mttaer in waht oredr the ltteers in a wrod are.\n",
    "2. **Stop words**: They are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc. Stop words are so commonly used that they carry very little useful information. So getting rid of them might be a good idea.\n",
    "\n",
    "Although the task can sound complicated, We can automate this using scikit-learn's CountVectorizer() to build a document-term matrix in a BOW style without the common stop words fairly easily.\n",
    "\n",
    "In cv= CountVectorizer(), CountVectorizer() randomly assigns a number to each word in a process called tokenizing. Then, it counts the number of occurrences of words and saves it to cv. At this point, we’ve only assigned a method to cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6d478ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absurd</th>\n",
       "      <th>academic</th>\n",
       "      <th>accitivties</th>\n",
       "      <th>accordance</th>\n",
       "      <th>according</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>...</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 899 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abilities  ability  able  abroad  absurd  academic  accitivties  \\\n",
       "0             0        0     0       0       0         0            0   \n",
       "1             0        0     0       0       0         0            0   \n",
       "2             0        0     0       0       0         0            0   \n",
       "3             0        0     0       0       0         0            0   \n",
       "4             0        0     0       0       0         0            0   \n",
       "...         ...      ...   ...     ...     ...       ...          ...   \n",
       "1105          0        0     0       0       0         0            0   \n",
       "1106          0        0     0       0       0         0            0   \n",
       "1107          0        0     0       0       0         0            0   \n",
       "1108          0        0     0       0       0         0            0   \n",
       "1109          0        0     0       0       0         0            0   \n",
       "\n",
       "      accordance  according  accordingly  ...  works  world  worth  write  \\\n",
       "0              0          0            0  ...      0      0      0      0   \n",
       "1              0          0            0  ...      0      0      0      0   \n",
       "2              0          0            0  ...      0      0      0      0   \n",
       "3              0          0            0  ...      0      0      0      0   \n",
       "4              0          0            0  ...      0      0      0      0   \n",
       "...          ...        ...          ...  ...    ...    ...    ...    ...   \n",
       "1105           0          0            0  ...      0      0      0      0   \n",
       "1106           0          0            0  ...      0      0      0      0   \n",
       "1107           0          0            0  ...      0      0      0      0   \n",
       "1108           0          0            0  ...      0      0      0      0   \n",
       "1109           0          0            0  ...      0      0      0      0   \n",
       "\n",
       "      writing  wrong  yeah  year  years  yes  \n",
       "0           0      0     0     0      0    0  \n",
       "1           0      0     0     0      0    0  \n",
       "2           0      0     0     0      0    0  \n",
       "3           0      0     0     0      0    0  \n",
       "4           0      0     0     0      0    0  \n",
       "...       ...    ...   ...   ...    ...  ...  \n",
       "1105        0      0     0     0      0    0  \n",
       "1106        0      0     0     0      0    0  \n",
       "1107        0      0     0     0      0    0  \n",
       "1108        0      0     0     0      0    0  \n",
       "1109        0      0     0     0      0    0  \n",
       "\n",
       "[1110 rows x 899 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are going to create a document-term matrix using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "commentCV = cv.fit_transform(evalClean['comment'])\n",
    "commentCV_dtm = pd.DataFrame(commentCV.toarray(), columns = cv.get_feature_names())\n",
    "\n",
    "commentCV_dtm.index = evalClean['comment'].index\n",
    "commentCV_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea6c94",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "As always, after building up our data, the next step is to take a look at the data and see what is going on here. First, it is worthwhile to check the distribution of the positive and negative comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48572326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>coursecontent</th>\n",
       "      <th>examination</th>\n",
       "      <th>extracurricular</th>\n",
       "      <th>labwork</th>\n",
       "      <th>library_facilities</th>\n",
       "      <th>teaching</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "      <td>154</td>\n",
       "      <td>132</td>\n",
       "      <td>130</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               comment                                                         \\\n",
       "category coursecontent examination extracurricular labwork library_facilities   \n",
       "eval                                                                            \n",
       "-1                  30          24              12      37                 31   \n",
       " 0                  27          31              19      16                 24   \n",
       " 1                 128         130             154     132                130   \n",
       "\n",
       "                   \n",
       "category teaching  \n",
       "eval               \n",
       "-1             13  \n",
       " 0             35  \n",
       " 1            137  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalClean.groupby(['eval','category']).count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0511b3",
   "metadata": {},
   "source": [
    "Overall, the distribution is quite skewed across all six categories -- the majority of the comments are positive. This may cause us some trouble in creating the classifier.\n",
    "\n",
    "Let's take a look at the document-term matrix. We can calculate the term frequency to get the most frequently used words in all documents. Below, we can find out the top 20 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "904aab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good          558\n",
       "university     59\n",
       "students       57\n",
       "excellent      56\n",
       "course         42\n",
       "pattern        40\n",
       "lab            39\n",
       "teachers       38\n",
       "activities     37\n",
       "knowledge      34\n",
       "content        31\n",
       "teaching       31\n",
       "checking       30\n",
       "paper          30\n",
       "work           29\n",
       "exam           28\n",
       "courses        28\n",
       "practical      27\n",
       "marks          27\n",
       "delivery       26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalCT = commentCV_dtm.sum()\n",
    "commentCV_dtm[totalCT.sort_values(ascending = False).index[:20]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a2f04",
   "metadata": {},
   "source": [
    "Further, we can calculate the inverse document frequency, which is the the number of times a word occurs in a corpus of documents. Combining the term frequency and the inverse document frequency (i.e., tf-idk), we can get a sense of how important each word is. Read more here:\n",
    "- TF-IDF from scratch in python on a real-world dataset: https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089#:~:text=TF%2DIDF%20stands%20for%20%E2%80%9CTerm,Information%20Retrieval%20and%20Text%20Mining\n",
    "- TF-IDK implementation in sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda89ec",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "One popular text analysis technique is called topic modeling. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics. Particularly, we will use one of the most frequently used TM methods, Latent Dirichlet Allocation (LDA).\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "To start with you probably need to install gensim through conda install -c conda-forge gensimand import a couple modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19fbab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b8614",
   "metadata": {},
   "source": [
    "Then we need to transpose the document term matrix to term-document matrix and use sparse.csr_matrix() to compress a matrix that is in rows and prepare the data in genism format and obtain a dictionary id2word of the locations of each term in the tdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25ddeb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = commentCV_dtm.transpose()\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "id2word = dict((v, p) for p, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017481d",
   "metadata": {},
   "source": [
    "Once we have the corpus and id2word ready, the rest of the topic modeling is simple: Pass everything to we need to LdaModel() and specify a few other parameters (e.g., the number of topics and the number of passes). Let's start the num_topic at 3, see if the results make sense.\n",
    "\n",
    "passes is the number of laps the model will take through corpus. The greater the number of passes, the more accurate the model will be. A lot of passes can be slow on a very large corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01101803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.310*\"good\" + 0.021*\"activities\" + 0.020*\"university\" + 0.018*\"students\" + 0.014*\"average\" + 0.013*\"teachers\" + 0.011*\"teaching\" + 0.010*\"best\" + 0.009*\"interaction\" + 0.008*\"punctuality\"'),\n",
       " (1,\n",
       "  '0.041*\"excellent\" + 0.030*\"course\" + 0.020*\"courses\" + 0.017*\"material\" + 0.017*\"content\" + 0.013*\"university\" + 0.012*\"time\" + 0.012*\"depth\" + 0.011*\"proper\" + 0.011*\"delivery\"'),\n",
       " (2,\n",
       "  '0.035*\"lab\" + 0.026*\"work\" + 0.022*\"marks\" + 0.020*\"paper\" + 0.020*\"practical\" + 0.019*\"exam\" + 0.017*\"pattern\" + 0.016*\"checking\" + 0.015*\"knowledge\" + 0.015*\"teachers\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=20)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d993427",
   "metadata": {},
   "source": [
    "Once the topic modeling technique is applied, your job as a human being, who can read natural language, is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics (increase or decrease), the terms in the document-term matrix, model parameters, or even try a different model. This unsupervised approach is quite similar to K-Means clustering.\n",
    "\n",
    "Now think about two things: (1) does the topic modeling makes sense? If yes, what types of topic it is trying to model? (2) play with the number of topics a little bit and see if you can get a more reasonable result.\n",
    "\n",
    "Further, you can explore stemming and lemmatization as ways to concentrate on the data goes into the document-term matrix (https://www.datacamp.com/community/tutorials/stemming-lemmatization-python). And you can also only focus on only one type of words (e.g., nouns) through tagging. See more details in the nltk package: https://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa124dbd",
   "metadata": {},
   "source": [
    "## Text Classifier\n",
    "Text classification is one of the most classical problem of NLP. One of the earlier examples using Naive Bayes is identifying spam emails. NLP classifiers are basically no different than all the classifiers we have seen before -- the most challenging part is the algorithm often has to work on a dataset with a lot of features/independent variables (i.e., all the terms in the document-term matrix) while the entries might be limited.\n",
    "\n",
    "We will first split the dataset into two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "898f51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xs_docs = evalClean['comment']\n",
    "Ys_evals = evalClean['eval']\n",
    "xs_training, xs_test, y_training, y_test = train_test_split(Xs_docs, Ys_evals, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411af885",
   "metadata": {},
   "source": [
    "Then we can call the classifier models and feed in the training data and labels. Here we are going to use the classic Naive Bayes algorithm. The only difference here is we are going to import the MultinomialNB because the label has more than two levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f894376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7477477477477478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Prepare the training features\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "features = cv.fit_transform(xs_training)\n",
    "\n",
    "# Train a multinomial Naive Bayes Model\n",
    "model = MultinomialNB()\n",
    "model.fit(features, y_training)\n",
    "\n",
    "# Prepare the testing xs.\n",
    "# Here we are using transform and fit_transform to standardize the data.\n",
    "# Read about the differences here: https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe\n",
    "feature_test = cv.transform(xs_test)\n",
    "\n",
    "# Print the model accuracy\n",
    "print(model.score(feature_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd8d2a",
   "metadata": {},
   "source": [
    "Not too bad, huh? We have achieved about 80% of accuracy. To compare the result, we can take a look at supported vector machine. The results are quite comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8955ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7387387387387387\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Prepare the training features\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "features = cv.fit_transform(xs_training)\n",
    "\n",
    "# Train SVM classifier\n",
    "model = svm.SVC()\n",
    "model.fit(features, y_training)\n",
    "\n",
    "# Prepare the testing xs\n",
    "feature_test = cv.transform(xs_test)\n",
    "\n",
    "# Print the model accuracy\n",
    "print(model.score(feature_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e3d76",
   "metadata": {},
   "source": [
    "Remember the labels are quite imbalanced, so resampling (under/oversampling) might worth a trial. Same as topic modeling, you can play with the stop words (what to include and what not to include), stemming, lemmatization, and tagging certain words. Through engineering what goes into the model can impact the model performance substantially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a86ee8",
   "metadata": {},
   "source": [
    "## End Notes\n",
    "In this ICE, we have seen some basics about NLP tasks. We’ve only scratched the surface of NLP by visiting some very classical models. Recent NLP has gone much further with neural networks and deep learning, which we don't have room to discuss -- for more NLP with deep learning, CS334 at Stanford by Chris Manning provides a much more thorough discussion and pretty much all the materials are available online."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
